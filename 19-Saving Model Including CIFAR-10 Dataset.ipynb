{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model Including CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 30, 30)        896       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 30, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 28, 28)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,227,050\n",
      "Trainable params: 3,227,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 356s 7ms/step - loss: 1.9429 - acc: 0.3004 - val_loss: 1.7546 - val_acc: 0.3847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f81fb518f98>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='valid', input_shape=(3, 32, 32), activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#epochs = 1\n",
    "epochs = 25\n",
    "lrate = 0.01\n",
    "decay = lrate / epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the model to the computer\n"
     ]
    }
   ],
   "source": [
    "#save model as Json\n",
    "model_json = model.to_json()\n",
    "with open(\"model_cifar10.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "#save the weights as hdf5\n",
    "model.save_weights(\"model_cifar10.h5\")\n",
    "\n",
    "print(\"Saved the model to the computer\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
